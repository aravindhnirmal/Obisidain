[[Keep/Colour/DEFAULT]] 

From Reference to predict data
Instance based learning lazy learning,not learn from dataset and it's memory from dataset
K is constant and nearest neighbour
Observad and given value compare each of 303 data given value is what we given and observe value
K<\n
K choose is called parameters turning if k is  change (depend upon the surrounding changes). K is high and very low it's give baisi
How to choose simple 
Sqrt of the dataset (303 na sqrt is 17) odd is better

Small dataset is well working
Euclid distance and if knn is 



Rff reduce risk of overfitting
Traing time is less 
Large database
multiple trees 
Majority of tree is choosen by random forest
2 apple and one mango

Entropy -measure of random ness or unpredictable in dataset high entropy next spilt the lower entropy information gain e1-e2
Classification dataset 

Which data is on root node for the heart disease or not
Take one attributes and 

The leaf nodes of the tree contain an output variable (y) which is used to make a prediction.Each root node represents a single input variable (x) and a split point on that variable
If the node contains many dataset and that node is spilt  child node is pure not spilt

Batch of if and else and many and many if and else statement and which is best for the root node spilt
Get the pure node
Maximum information gain 
Ig increase and entropy low or( impurity)
Entropy formula log and entropy high it's uncertain and 1 high possibility of entropy 

Entropy method very lowest attributes ta parents node irukkum
Each split is based on a condition or threshold, which maximizes the information gain or minimizes the entropy of the daThe leaf nodes of the tree contain an output variable (y) which is used to make a prediction.The algorithm works by randomly selecting subsets of features from the input dataset, and then constructing decision trees based on these subsets


 How decision tree work
 1. Classify the different from choasos high entropy and trained dataset and spilt the how
 2.  








